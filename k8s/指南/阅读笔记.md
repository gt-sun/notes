[TOC]

## docker-cli-to-kubectl/

```
# start the pod running nginx
$ kubectl run --image=nginx nginx-app --port=80 --env="DOMAIN=cluster"
deployment "nginx-app" created
```

`kubectl run` creates a *Deployment*.

Now, we can expose a new *Service* with the *deployment* created above:

```
# expose a port through with a service
$ kubectl expose deployment nginx-app --port=80 --name=nginx-http
service "nginx-http" exposed
```

We start a *Deployment* for your container, it will be restarted if you terminate the attached process (e.g. ctrl-c). To destroy the *Deployment* (and its *pods*) you need to run `kubectl delete deployment <name>`


## Tasks

https://kubernetes.io/docs/tasks/

### Configuring Pods and Containers

#### 定义环境变量

yaml文件：

```
apiVersion: v1
kind: Pod
metadata:
  name: envar-demo
  labels:
    purpose: demonstrate-envars
spec:
  containers:
  - name: envar-demo-container
    image: gcr.io/google-samples/node-hello:1.0
    env:
    - name: DEMO_GREETING
      value: "Hello from the environment"
```


#### 定义command和arguments

**override the default command and arguments provided by the container image.**

yaml文件：

```
apiVersion: v1
kind: Pod
metadata:
  name: command-demo
  labels:
    purpose: demonstrate-command
spec:
  containers:
  - name: command-demo-container
    image: debian
    command: ["printenv"]
    args: ["HOSTNAME", "KUBERNETES_PORT"]
```

使用环境变量：

```
env:
- name: MESSAGE
  value: "hello world"
command: ["/bin/echo"]
args: ["$(MESSAGE)"]
```

在子shell里：

```
command: ["/bin/sh"]
args: ["-c", "while true; do echo hello; sleep 10;done"]
```

#### 分配CPU和RAM

** If a container exceeds its RAM limit, it is terminated.  If a container exceeds its CPU limit, it becomes a candidate for having its CPU use throttled.**

yaml文件：

```
apiVersion: v1
kind: Pod
metadata:
  name: cpu-ram-demo
spec:
  containers:
  - name: cpu-ram-demo-container
    image: gcr.io/google-samples/node-hello:1.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "1"
```

The CPU resource is measured in cpus. Fractional values are allowed. You can use the suffix m to mean mili. For example 100m cpu is 100 milicpu, and is the same as 0.1 cpu.
The RAM resource is measured in bytes. You can express RAM as a plain integer or a fixed-point integer with one of these suffixes: E, P, T, G, M, K, Ei, Pi, Ti, Gi, Mi, Ki. For example, the following represent approximately the same value:

```
128974848, 129e6, 129M , 123Mi
```


If you don’t specify a RAM limit, Kubernetes places no upper bound on the amount of RAM a Container can use. A Container could use all the RAM available on the Node where the Container is running. Similarly, if you don’t specify a CPU limit, Kubernetes places no upper bound on CPU resources, and a Container could use all of the CPU resources available on the Node.
Default limits are applied according to a limit range for the default namespace. You can use `kubectl describe limitrange limits` to see the default limits.

#### Use a Volume for Storage

This Pod has a Volume of type [emptyDir](https://kubernetes.io/docs/user-guide/volumes/#emptydir) that lasts for the life of the Pod, even if the Container terminates and restarts.

```
apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: redis-storage
      mountPath: /data/redis #这个是容器里面的目录
  volumes:
  - name: redis-storage
    emptyDir: {}
```

#### Use secret data

```
echo 'my-app' | base64
echo '39528$vdg7Jb' | base64
```

The output shows that the base-64 representation of your username is `bXktYXBwCg==`, and the base-64 representation of your password is `Mzk1MjgkdmRnN0piCg==`.

**Creating a Secret:**

```
apiVersion: v1
kind: Secret
metadata:
  name: test-secret
data:
  username: bXktYXBwCg==
  password: Mzk1MjgkdmRnN0piCg==
```

`kubectl create -f http://k8s.io/docs/tasks/administer-cluster/secret.yaml`
`kubectl get secret test-secret`

**Creating a Pod that has access to the secret data through a Volume**

```go
apiVersion: v1
kind: Pod
metadata:
  name: secret-test-pod
spec:
  containers:
    - name: test-container
      image: nginx
      volumeMounts:
          # name must match the volume name below
          - name: secret-volume
            mountPath: /etc/secret-volume
  # The secret data is exposed to Containers in the Pod through a Volume.
  volumes:
    - name: secret-volume
      secret:
        secretName: test-secret
```

然后进入容器，

```
root@secret-test-pod:/etc/secret-volume# cat username password
 my-app
 39528$vdg7Jb
```

**Creating a Pod that has access to the secret data through environment variables**

```
apiVersion: v1
kind: Pod
metadata:
  name: secret-envars-test-pod
spec:
  containers:
  - name: envars-test-container
    image: nginx
    env:
    - name: SECRET_USERNAME
      valueFrom:
        secretKeyRef:
          name: test-secret
          key: username
    - name: SECRET_PASSWORD
      valueFrom:
        secretKeyRef:
          name: test-secret
          key: password
```

然后进入容器：

```
root@secret-envars-test-pod:/# printenv
 ...
 SECRET_USERNAME=my-app
 ...
 SECRET_PASSWORD=39528$vdg7Jb
```

#### Configuring Liveness and Readiness Probes

监控容器里的application

- 通过文件监控

yaml文件：

```
apiVersion: v1
kind: Pod

metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:

  - name: liveness

    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600

    image: gcr.io/google_containers/busybox

    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
```

If the command succeeds, it returns 0, and the kubelet considers the Container to be alive and healthy. If the command returns a non-zero value, the kubelet kills the Container and restarts it.

- Defining a liveness HTTP request

yaml文件：

```
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:

  - name: liveness

    args:
    - /server

    image: gcr.io/google_containers/liveness

    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
          - name: X-Custom-Header
            value: Awesome
      initialDelaySeconds: 3
      periodSeconds: 3
```

Any code greater than or equal to 200 and less than 400 indicates success. Any other code indicates failure.

You can use a named `ContainerPort` for HTTP liveness checks:

```
ports:
- name: liveness-port
  containerPort: 8080
  hostPort: 8080

livenessProbe:
  httpGet:
  path: /healthz
  port: liveness-port
```

#### Communicating Between Containers Running in the Same Pod

https://kubernetes.io/docs/tasks/configure-pod-container/communicate-containers-same-pod/

#### Attaching Handlers to Container Lifecycle Events

yaml文件：

```
apiVersion: v1
kind: Pod
metadata:
  name: lifecycle-demo
spec:
  containers:
  - name: lifecycle-demo-container
    image: nginx

    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
      preStop:
        exec:
          command: ["/usr/sbin/nginx","-s","quit"]
```

Kubernetes sends the postStart event immediately after the Container is created. There is no guarantee, however, that the postStart handler is called before the Container’s entrypoint is called. The postStart handler runs asynchronously relative to the Container’s code, but Kubernetes’ management of the container blocks until the postStart handler completes. The Container’s status is not set to RUNNING until the postStart handler completes.
Kubernetes sends the preStop event immediately before the Container is terminated. Kubernetes’ management of the Container blocks until the preStop handler completes, unless the Pod’s grace period expires. For more details, see Termination of Pods.

### Accessing Applications in a Cluster

#### Using Port Forwarding to Access Applications in a Cluster



```
kubectl port-forward redis-master 6379:6379

 I0710 14:43:38.274550    3655 portforward.go:225] Forwarding from 127.0.0.1:6379 -> 6379
 I0710 14:43:38.274797    3655 portforward.go:225] Forwarding from [::1]:6379 -> 6379
```

Connections made to local port 6379 are forwarded to port 6379 of the pod that is running the Redis server. With this connection in place you can use your local workstation to debug the database that is running in the pod.
